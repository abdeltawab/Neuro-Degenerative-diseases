"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[5268],{7295:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>t,default:()=>a,frontMatter:()=>i,metadata:()=>o,toc:()=>d});var l=s(4848),r=s(8453);const i={sidebar_label:"rnn_vae",title:"model.rnn_vae"},t=void 0,o={id:"reference/model/rnn_vae",title:"model.rnn_vae",description:"logger\\_config",source:"@site/docs/reference/model/rnn_vae.md",sourceDirName:"reference/model",slug:"/reference/model/rnn_vae",permalink:"/VAME/docs/reference/model/rnn_vae",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{sidebar_label:"rnn_vae",title:"model.rnn_vae"},sidebar:"docsSidebar",previous:{title:"rnn_model",permalink:"/VAME/docs/reference/model/rnn_model"},next:{title:"pipeline",permalink:"/VAME/docs/reference/pipeline"}},c={},d=[{value:"logger_config",id:"logger_config",level:4},{value:"logger",id:"logger",level:4},{value:"tqdm_to_logger",id:"tqdm_to_logger",level:4},{value:"use_gpu",id:"use_gpu",level:4},{value:"reconstruction_loss",id:"reconstruction_loss",level:4},{value:"future_reconstruction_loss",id:"future_reconstruction_loss",level:4},{value:"cluster_loss",id:"cluster_loss",level:4},{value:"kullback_leibler_loss",id:"kullback_leibler_loss",level:4},{value:"kl_annealing",id:"kl_annealing",level:4},{value:"gaussian",id:"gaussian",level:4},{value:"train",id:"train",level:4},{value:"test",id:"test",level:4},{value:"train_model",id:"train_model",level:4}];function h(e){const n={a:"a",code:"code",h4:"h4",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(n.h4,{id:"logger_config",children:"logger_config"}),"\n",(0,l.jsx)(n.h4,{id:"logger",children:"logger"}),"\n",(0,l.jsx)(n.h4,{id:"tqdm_to_logger",children:"tqdm_to_logger"}),"\n",(0,l.jsx)(n.h4,{id:"use_gpu",children:"use_gpu"}),"\n",(0,l.jsx)(n.h4,{id:"reconstruction_loss",children:"reconstruction_loss"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"def reconstruction_loss(x: torch.Tensor, x_tilde: torch.Tensor,\n                        reduction: str) -> torch.Tensor\n"})}),"\n",(0,l.jsx)(n.p,{children:"Compute the reconstruction loss between input and reconstructed data."}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"x"})," (",(0,l.jsx)(n.code,{children:"torch.Tensor"}),"): Input data tensor."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"x_tilde"})," (",(0,l.jsx)(n.code,{children:"torch.Tensor"}),"): Reconstructed data tensor."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"reduction"})," (",(0,l.jsx)(n.code,{children:"str"}),"): Type of reduction for the loss."]}),"\n"]}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Returns"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"torch.Tensor"}),": Reconstruction loss."]}),"\n"]}),"\n",(0,l.jsx)(n.h4,{id:"future_reconstruction_loss",children:"future_reconstruction_loss"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"def future_reconstruction_loss(x: torch.Tensor, x_tilde: torch.Tensor,\n                               reduction: str) -> torch.Tensor\n"})}),"\n",(0,l.jsx)(n.p,{children:"Compute the future reconstruction loss between input and predicted future data."}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"x"})," (",(0,l.jsx)(n.code,{children:"torch.Tensor"}),"): Input future data tensor."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"x_tilde"})," (",(0,l.jsx)(n.code,{children:"torch.Tensor"}),"): Reconstructed future data tensor."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"reduction"})," (",(0,l.jsx)(n.code,{children:"str"}),"): Type of reduction for the loss."]}),"\n"]}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Returns"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"torch.Tensor"}),": Future reconstruction loss."]}),"\n"]}),"\n",(0,l.jsx)(n.h4,{id:"cluster_loss",children:"cluster_loss"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"def cluster_loss(H: torch.Tensor, kloss: int, lmbda: float,\n                 batch_size: int) -> torch.Tensor\n"})}),"\n",(0,l.jsx)(n.p,{children:"Compute the cluster loss."}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"H"})," (",(0,l.jsx)(n.code,{children:"torch.Tensor"}),"): Latent representation tensor."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"kloss"})," (",(0,l.jsx)(n.code,{children:"int"}),"): Number of clusters."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"lmbda"})," (",(0,l.jsx)(n.code,{children:"float"}),"): Lambda value for the loss."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"batch_size"})," (",(0,l.jsx)(n.code,{children:"int"}),"): Size of the batch."]}),"\n"]}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Returns"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"torch.Tensor"}),": Cluster loss."]}),"\n"]}),"\n",(0,l.jsx)(n.h4,{id:"kullback_leibler_loss",children:"kullback_leibler_loss"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"def kullback_leibler_loss(mu: torch.Tensor,\n                          logvar: torch.Tensor) -> torch.Tensor\n"})}),"\n",(0,l.jsxs)(n.p,{children:["Compute the Kullback-Leibler divergence loss.\nSee Appendix B from VAE paper: Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014 - ",(0,l.jsx)(n.a,{href:"https://arxiv.org/abs/1312.6114",children:"https://arxiv.org/abs/1312.6114"})]}),"\n",(0,l.jsx)(n.p,{children:"Formula: 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)"}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"mu"})," (",(0,l.jsx)(n.code,{children:"torch.Tensor"}),"): Mean of the latent distribution."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"logvar"})," (",(0,l.jsx)(n.code,{children:"torch.Tensor"}),"): Log variance of the latent distribution."]}),"\n"]}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Returns"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"torch.Tensor"}),": Kullback-Leibler divergence loss."]}),"\n"]}),"\n",(0,l.jsx)(n.h4,{id:"kl_annealing",children:"kl_annealing"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"def kl_annealing(epoch: int, kl_start: int, annealtime: int,\n                 function: str) -> float\n"})}),"\n",(0,l.jsx)(n.p,{children:"Anneal the Kullback-Leibler loss to let the model learn first the reconstruction of the data\nbefore the KL loss term gets introduced."}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"epoch"})," (",(0,l.jsx)(n.code,{children:"int"}),"): Current epoch number."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"kl_start"})," (",(0,l.jsx)(n.code,{children:"int"}),"): Epoch number to start annealing the loss."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"annealtime"})," (",(0,l.jsx)(n.code,{children:"int"}),"): Annealing time."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"function"})," (",(0,l.jsx)(n.code,{children:"str"}),"): Annealing function type."]}),"\n"]}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Returns"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"float"}),": Annealed weight value for the loss."]}),"\n"]}),"\n",(0,l.jsx)(n.h4,{id:"gaussian",children:"gaussian"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"def gaussian(ins: torch.Tensor,\n             is_training: bool,\n             seq_len: int,\n             std_n: float = 0.8) -> torch.Tensor\n"})}),"\n",(0,l.jsx)(n.p,{children:"Add Gaussian noise to the input data."}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"ins"})," (",(0,l.jsx)(n.code,{children:"torch.Tensor"}),"): Input data tensor."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"is_training"})," (",(0,l.jsx)(n.code,{children:"bool"}),"): Whether it is training mode."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"seq_len"})," (",(0,l.jsx)(n.code,{children:"int"}),"): Length of the sequence."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"std_n"})," (",(0,l.jsx)(n.code,{children:"float"}),"): Standard deviation for the Gaussian noise."]}),"\n"]}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Returns"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"torch.Tensor"}),": Noisy input data tensor."]}),"\n"]}),"\n",(0,l.jsx)(n.h4,{id:"train",children:"train"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"def train(train_loader: Data.DataLoader, epoch: int, model: nn.Module,\n          optimizer: torch.optim.Optimizer, anneal_function: str, BETA: float,\n          kl_start: int, annealtime: int, seq_len: int, future_decoder: bool,\n          future_steps: int, scheduler: torch.optim.lr_scheduler._LRScheduler,\n          mse_red: str, mse_pred: str, kloss: int, klmbda: float, bsize: int,\n          noise: bool) -> Tuple[float, float, float, float, float, float]\n"})}),"\n",(0,l.jsx)(n.p,{children:"Train the model."}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"train_loader"})," (",(0,l.jsx)(n.code,{children:"DataLoader"}),"): Training data loader."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"epoch"})," (",(0,l.jsx)(n.code,{children:"int"}),"): Current epoch number."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"model"})," (",(0,l.jsx)(n.code,{children:"nn.Module"}),"): Model to be trained."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"optimizer"})," (",(0,l.jsx)(n.code,{children:"Optimizer"}),"): Optimizer for training."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"anneal_function"})," (",(0,l.jsx)(n.code,{children:"str"}),"): Annealing function type."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"BETA"})," (",(0,l.jsx)(n.code,{children:"float"}),"): Beta value for the loss."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"kl_start"})," (",(0,l.jsx)(n.code,{children:"int"}),"): Epoch number to start annealing the loss."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"annealtime"})," (",(0,l.jsx)(n.code,{children:"int"}),"): Annealing time."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"seq_len"})," (",(0,l.jsx)(n.code,{children:"int"}),"): Length of the sequence."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"future_decoder"})," (",(0,l.jsx)(n.code,{children:"bool"}),"): Whether a future decoder is used."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"future_steps"})," (",(0,l.jsx)(n.code,{children:"int"}),"): Number of future steps to predict."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"scheduler"})," (",(0,l.jsx)(n.code,{children:"lr_scheduler._LRScheduler"}),"): Learning rate scheduler."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"mse_red"})," (",(0,l.jsx)(n.code,{children:"str"}),"): Reduction type for MSE reconstruction loss."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"mse_pred"})," (",(0,l.jsx)(n.code,{children:"str"}),"): Reduction type for MSE prediction loss."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"kloss"})," (",(0,l.jsx)(n.code,{children:"int"}),"): Number of clusters for cluster loss."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"klmbda"})," (",(0,l.jsx)(n.code,{children:"float"}),"): Lambda value for cluster loss."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"bsize"})," (",(0,l.jsx)(n.code,{children:"int"}),"): Size of the batch."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"noise"})," (",(0,l.jsx)(n.code,{children:"bool"}),"): Whether to add Gaussian noise to the input."]}),"\n"]}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Returns"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"Tuple[float, float, float, float, float, float]"}),": Kullback-Leibler weight, train loss, K-means loss, KL loss,\nMSE loss, future loss."]}),"\n"]}),"\n",(0,l.jsx)(n.h4,{id:"test",children:"test"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"def test(test_loader: Data.DataLoader, model: nn.Module, BETA: float,\n         kl_weight: float, seq_len: int, mse_red: str, kloss: str,\n         klmbda: float, future_decoder: bool,\n         bsize: int) -> Tuple[float, float, float]\n"})}),"\n",(0,l.jsx)(n.p,{children:"Evaluate the model on the test dataset."}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"test_loader"})," (",(0,l.jsx)(n.code,{children:"DataLoader"}),"): DataLoader for the test dataset."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"model"})," (",(0,l.jsx)(n.code,{children:"nn.Module"}),"): The trained model."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"BETA"})," (",(0,l.jsx)(n.code,{children:"float"}),"): Beta value for the VAE loss."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"kl_weight"})," (",(0,l.jsx)(n.code,{children:"float"}),"): Weighting factor for the KL divergence loss."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"seq_len"})," (",(0,l.jsx)(n.code,{children:"int"}),"): Length of the sequence."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"mse_red"})," (",(0,l.jsx)(n.code,{children:"str"}),"): Reduction method for the MSE loss."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"kloss"})," (",(0,l.jsx)(n.code,{children:"str"}),"): Loss function for K-means clustering."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"klmbda"})," (",(0,l.jsx)(n.code,{children:"float"}),"): Lambda value for K-means loss."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"future_decoder"})," (",(0,l.jsx)(n.code,{children:"bool"}),"): Flag indicating whether to use a future decoder."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsxs)(n.strong,{children:["bsize ",":int"]}),": Batch size."]}),"\n"]}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Returns"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"Tuple[float, float, float]"}),": Tuple containing MSE loss per item, total test loss per item,\nand K-means loss weighted by the kl_weight."]}),"\n"]}),"\n",(0,l.jsx)(n.h4,{id:"train_model",children:"train_model"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"@save_state(model=TrainModelFunctionSchema)\ndef train_model(config: dict, save_logs: bool = False) -> None\n"})}),"\n",(0,l.jsx)(n.p,{children:'Train Variational Autoencoder using the configuration file values.\nFills in the values in the "train_model" key of the states.json file.\nCreates files at:'}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["project_name/","\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["model/","\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["best_model/","\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["snapshots/","\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"model_name_Project_epoch_0.pkl"}),"\n",(0,l.jsx)(n.li,{children:"..."}),"\n"]}),"\n"]}),"\n",(0,l.jsx)(n.li,{children:"model_name_Project.pkl"}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["model_losses/","\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"fut_losses_VAME.npy"}),"\n",(0,l.jsx)(n.li,{children:"kl_losses_VAME.npy"}),"\n",(0,l.jsx)(n.li,{children:"kmeans_losses_VAME.npy"}),"\n",(0,l.jsx)(n.li,{children:"mse_test_losses_VAME.npy"}),"\n",(0,l.jsx)(n.li,{children:"mse_train_losses_VAME.npy"}),"\n",(0,l.jsx)(n.li,{children:"test_losses_VAME.npy"}),"\n",(0,l.jsx)(n.li,{children:"train_losses_VAME.npy"}),"\n",(0,l.jsx)(n.li,{children:"weight_values_VAME.npy"}),"\n"]}),"\n"]}),"\n",(0,l.jsx)(n.li,{children:"pretrained_model/"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"config"})," (",(0,l.jsx)(n.code,{children:"dict"}),"): Configuration dictionary."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"save_logs"})," (",(0,l.jsx)(n.code,{children:"bool, optional"}),"): Whether to save the logs, by default False."]}),"\n"]}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Returns"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.code,{children:"None"})}),"\n"]})]})}function a(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,l.jsx)(n,{...e,children:(0,l.jsx)(h,{...e})}):h(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>t,x:()=>o});var l=s(6540);const r={},i=l.createContext(r);function t(e){const n=l.useContext(i);return l.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),l.createElement(i.Provider,{value:n},e.children)}}}]);