"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[1757],{4882:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>t,contentTitle:()=>l,default:()=>a,frontMatter:()=>d,metadata:()=>o,toc:()=>c});var s=r(4848),i=r(8453);const d={sidebar_label:"rnn_model",title:"model.rnn_model"},l=void 0,o={id:"reference/model/rnn_model",title:"model.rnn_model",description:"Encoder Objects",source:"@site/docs/reference/model/rnn_model.md",sourceDirName:"reference/model",slug:"/reference/model/rnn_model",permalink:"/VAME/docs/reference/model/rnn_model",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{sidebar_label:"rnn_model",title:"model.rnn_model"},sidebar:"docsSidebar",previous:{title:"evaluate",permalink:"/VAME/docs/reference/model/evaluate"},next:{title:"rnn_vae",permalink:"/VAME/docs/reference/model/rnn_vae"}},t={},c=[{value:"Encoder Objects",id:"encoder-objects",level:2},{value:"__init__",id:"__init__",level:4},{value:"forward",id:"forward",level:4},{value:"Lambda Objects",id:"lambda-objects",level:2},{value:"__init__",id:"__init__-1",level:4},{value:"forward",id:"forward-1",level:4},{value:"Decoder Objects",id:"decoder-objects",level:2},{value:"__init__",id:"__init__-2",level:4},{value:"forward",id:"forward-2",level:4},{value:"Decoder_Future Objects",id:"decoder_future-objects",level:2},{value:"__init__",id:"__init__-3",level:4},{value:"forward",id:"forward-3",level:4},{value:"RNN_VAE Objects",id:"rnn_vae-objects",level:2},{value:"__init__",id:"__init__-4",level:4},{value:"forward",id:"forward-4",level:4}];function h(e){const n={code:"code",h2:"h2",h4:"h4",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h2,{id:"encoder-objects",children:"Encoder Objects"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"class Encoder(nn.Module)\n"})}),"\n",(0,s.jsx)(n.p,{children:"Encoder module of the Variational Autoencoder."}),"\n",(0,s.jsx)(n.h4,{id:"__init__",children:"__init__"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"def __init__(NUM_FEATURES: int, hidden_size_layer_1: int,\n             hidden_size_layer_2: int, dropout_encoder: float)\n"})}),"\n",(0,s.jsx)(n.p,{children:"Initialize the Encoder module."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"NUM_FEATURES"})," (",(0,s.jsx)(n.code,{children:"int"}),"): Number of input features."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"hidden_size_layer_1"})," (",(0,s.jsx)(n.code,{children:"int"}),"): Size of the first hidden layer."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"hidden_size_layer_2"})," (",(0,s.jsx)(n.code,{children:"int"}),"): Size of the second hidden layer."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"dropout_encoder"})," (",(0,s.jsx)(n.code,{children:"float"}),"): Dropout rate for regularization."]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"forward",children:"forward"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"def forward(inputs: torch.Tensor) -> torch.Tensor\n"})}),"\n",(0,s.jsx)(n.p,{children:"Forward pass of the Encoder module."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"inputs"})," (",(0,s.jsx)(n.code,{children:"torch.Tensor"}),"): Input tensor of shape (batch_size, sequence_length, num_features)."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Returns"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"torch.Tensor:"}),": Encoded representation tensor of shape (batch_size, hidden_size_layer_1 * 4)."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"lambda-objects",children:"Lambda Objects"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"class Lambda(nn.Module)\n"})}),"\n",(0,s.jsx)(n.p,{children:"Lambda module for computing the latent space parameters."}),"\n",(0,s.jsx)(n.h4,{id:"__init__-1",children:"__init__"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"def __init__(ZDIMS: int, hidden_size_layer_1: int, softplus: bool)\n"})}),"\n",(0,s.jsx)(n.p,{children:"Initialize the Lambda module."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"ZDIMS"})," (",(0,s.jsx)(n.code,{children:"int"}),"): Size of the latent space."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"hidden_size_layer_1"})," (",(0,s.jsx)(n.code,{children:"int"}),"): Size of the first hidden layer."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"hidden_size_layer_2"})," (",(0,s.jsx)(n.code,{children:"int, deprecated"}),"): Size of the second hidden layer."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"softplus"})," (",(0,s.jsx)(n.code,{children:"bool"}),"): Whether to use softplus activation for logvar."]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"forward-1",children:"forward"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"def forward(\n        hidden: torch.Tensor\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]\n"})}),"\n",(0,s.jsx)(n.p,{children:"Forward pass of the Lambda module."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"hidden"})," (",(0,s.jsx)(n.code,{children:"torch.Tensor"}),"): Hidden representation tensor of shape (batch_size, hidden_size_layer_1 * 4)."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Returns"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"tuple[torch.Tensor, torch.Tensor, torch.Tensor]"}),": Latent space tensor, mean tensor, logvar tensor."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"decoder-objects",children:"Decoder Objects"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"class Decoder(nn.Module)\n"})}),"\n",(0,s.jsx)(n.p,{children:"Decoder module of the Variational Autoencoder."}),"\n",(0,s.jsx)(n.h4,{id:"__init__-2",children:"__init__"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"def __init__(TEMPORAL_WINDOW: int, ZDIMS: int, NUM_FEATURES: int,\n             hidden_size_rec: int, dropout_rec: float)\n"})}),"\n",(0,s.jsx)(n.p,{children:"Initialize the Decoder module."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"TEMPORAL_WINDOW"})," (",(0,s.jsx)(n.code,{children:"int"}),"): Size of the temporal window."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"ZDIMS"})," (",(0,s.jsx)(n.code,{children:"int"}),"): Size of the latent space."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"NUM_FEATURES"})," (",(0,s.jsx)(n.code,{children:"int"}),"): Number of input features."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"hidden_size_rec"})," (",(0,s.jsx)(n.code,{children:"int"}),"): Size of the recurrent hidden layer."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"dropout_rec"})," (",(0,s.jsx)(n.code,{children:"float"}),"): Dropout rate for regularization."]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"forward-2",children:"forward"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"def forward(inputs: torch.Tensor, z: torch.Tensor) -> torch.Tensor\n"})}),"\n",(0,s.jsx)(n.p,{children:"Forward pass of the Decoder module."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"inputs"})," (",(0,s.jsx)(n.code,{children:"torch.Tensor"}),"): Input tensor of shape (batch_size, seq_len, ZDIMS)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"z"})," (",(0,s.jsx)(n.code,{children:"torch.Tensor"}),"): Latent space tensor of shape (batch_size, ZDIMS)."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Returns"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"torch.Tensor:"}),": Decoded output tensor of shape (batch_size, seq_len, NUM_FEATURES)."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"decoder_future-objects",children:"Decoder_Future Objects"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"class Decoder_Future(nn.Module)\n"})}),"\n",(0,s.jsx)(n.p,{children:"Decoder module for predicting future sequences."}),"\n",(0,s.jsx)(n.h4,{id:"__init__-3",children:"__init__"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"def __init__(TEMPORAL_WINDOW: int, ZDIMS: int, NUM_FEATURES: int,\n             FUTURE_STEPS: int, hidden_size_pred: int, dropout_pred: float)\n"})}),"\n",(0,s.jsx)(n.p,{children:"Initialize the Decoder_Future module."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"TEMPORAL_WINDOW"})," (",(0,s.jsx)(n.code,{children:"int"}),"): Size of the temporal window."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"ZDIMS"})," (",(0,s.jsx)(n.code,{children:"int"}),"): Size of the latent space."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"NUM_FEATURES"})," (",(0,s.jsx)(n.code,{children:"int"}),"): Number of input features."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"FUTURE_STEPS"})," (",(0,s.jsx)(n.code,{children:"int"}),"): Number of future steps to predict."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"hidden_size_pred"})," (",(0,s.jsx)(n.code,{children:"int"}),"): Size of the prediction hidden layer."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"dropout_pred"})," (",(0,s.jsx)(n.code,{children:"float"}),"): Dropout rate for regularization."]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"forward-3",children:"forward"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"def forward(inputs: torch.Tensor, z: torch.Tensor) -> torch.Tensor\n"})}),"\n",(0,s.jsx)(n.p,{children:"Forward pass of the Decoder_Future module."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"inputs"})," (",(0,s.jsx)(n.code,{children:"torch.Tensor"}),"): Input tensor of shape (batch_size, seq_len, ZDIMS)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"z"})," (",(0,s.jsx)(n.code,{children:"torch.Tensor"}),"): Latent space tensor of shape (batch_size, ZDIMS)."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Returns"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"torch.Tensor:"}),": Predicted future tensor of shape (batch_size, FUTURE_STEPS, NUM_FEATURES)."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"rnn_vae-objects",children:"RNN_VAE Objects"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"class RNN_VAE(nn.Module)\n"})}),"\n",(0,s.jsx)(n.p,{children:"Variational Autoencoder module."}),"\n",(0,s.jsx)(n.h4,{id:"__init__-4",children:"__init__"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"def __init__(TEMPORAL_WINDOW: int, ZDIMS: int, NUM_FEATURES: int,\n             FUTURE_DECODER: bool, FUTURE_STEPS: int, hidden_size_layer_1: int,\n             hidden_size_layer_2: int, hidden_size_rec: int,\n             hidden_size_pred: int, dropout_encoder: float, dropout_rec: float,\n             dropout_pred: float, softplus: bool)\n"})}),"\n",(0,s.jsx)(n.p,{children:"Initialize the VAE module."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"TEMPORAL_WINDOW"})," (",(0,s.jsx)(n.code,{children:"int"}),"): Size of the temporal window."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"ZDIMS"})," (",(0,s.jsx)(n.code,{children:"int"}),"): Size of the latent space."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"NUM_FEATURES"})," (",(0,s.jsx)(n.code,{children:"int"}),"): Number of input features."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"FUTURE_DECODER"})," (",(0,s.jsx)(n.code,{children:"bool"}),"): Whether to include a future decoder."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"FUTURE_STEPS"})," (",(0,s.jsx)(n.code,{children:"int"}),"): Number of future steps to predict."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"hidden_size_layer_1"})," (",(0,s.jsx)(n.code,{children:"int"}),"): Size of the first hidden layer."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"hidden_size_layer_2"})," (",(0,s.jsx)(n.code,{children:"int"}),"): Size of the second hidden layer."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"hidden_size_rec"})," (",(0,s.jsx)(n.code,{children:"int"}),"): Size of the recurrent hidden layer."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"hidden_size_pred"})," (",(0,s.jsx)(n.code,{children:"int"}),"): Size of the prediction hidden layer."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"dropout_encoder"})," (",(0,s.jsx)(n.code,{children:"float"}),"): Dropout rate for encoder."]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"forward-4",children:"forward"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"def forward(seq: torch.Tensor) -> tuple\n"})}),"\n",(0,s.jsx)(n.p,{children:"Forward pass of the VAE."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Parameters"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"seq"})," (",(0,s.jsx)(n.code,{children:"torch.Tensor"}),"): Input sequence tensor of shape (batch_size, seq_len, NUM_FEATURES)."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Returns"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"Tuple containing:"}),": - If FUTURE_DECODER is True:","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"prediction (torch.Tensor): Reconstructed input sequence tensor."}),"\n",(0,s.jsx)(n.li,{children:"future (torch.Tensor): Predicted future sequence tensor."}),"\n",(0,s.jsx)(n.li,{children:"z (torch.Tensor): Latent representation tensor."}),"\n",(0,s.jsx)(n.li,{children:"mu (torch.Tensor): Mean of the latent distribution tensor."}),"\n",(0,s.jsx)(n.li,{children:"logvar (torch.Tensor): Log variance of the latent distribution tensor."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["If FUTURE_DECODER is False:","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"prediction (torch.Tensor): Reconstructed input sequence tensor."}),"\n",(0,s.jsx)(n.li,{children:"z (torch.Tensor): Latent representation tensor."}),"\n",(0,s.jsx)(n.li,{children:"mu (torch.Tensor): Mean of the latent distribution tensor."}),"\n",(0,s.jsx)(n.li,{children:"logvar (torch.Tensor): Log variance of the latent distribution tensor."}),"\n"]}),"\n"]}),"\n"]})]})}function a(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>l,x:()=>o});var s=r(6540);const i={},d=s.createContext(i);function l(e){const n=s.useContext(d);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),s.createElement(d.Provider,{value:n},e.children)}}}]);